{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64379d2",
   "metadata": {},
   "source": [
    "# Problem 3(b): Viterbi Decoding vs. Smoothing\n",
    "\n",
    "Viterbiâ€™s algorithm finds the most likely *state trajectory* of the hidden Markov model (HMM)\n",
    "given a sequence of observations \\(Y_1,\\dots,Y_t\\). Specifically, it solves the decoding problem\n",
    "\n",
    "$$\n",
    "(x_1^*, \\dots, x_t^*)\n",
    "=\n",
    "\\arg\\max_{(x_1,\\dots,x_t)}\n",
    "P(X_1 = x_1, \\dots, X_t = x_t \\mid Y_1, \\dots, Y_t).\n",
    "$$\n",
    "\n",
    "On the other hand, smoothing computes the marginal posterior distribution of the state at\n",
    "each time step and selects the most likely state independently at each time:\n",
    "\n",
    "$$\n",
    "\\hat{x}_k = \\arg\\max_x P(X_k = x \\mid Y_1, \\dots, Y_t),\n",
    "$$\n",
    "\n",
    "resulting in the sequence\n",
    "$$\n",
    "(\\hat{x}_1, \\dots, \\hat{x}_t).\n",
    "$$\n",
    "\n",
    "In general, these two sequences are **not the same**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why the two solutions are different in general\n",
    "\n",
    "The key reason is that the two methods optimize **different objective functions**.\n",
    "\n",
    "- **Viterbi decoding** maximizes the *joint posterior probability* of the entire state trajectory.\n",
    "  It explicitly takes into account:\n",
    "  - the initial state distribution,\n",
    "  - the state transition probabilities,\n",
    "  - and the observation likelihoods,\n",
    "  over all time steps simultaneously.\n",
    "\n",
    "- **Smoothing with pointwise MAP** maximizes the *marginal posterior probability* at each time\n",
    "  step independently. The most likely state at time \\(k\\) is chosen without considering whether\n",
    "  this choice is consistent with high-probability transitions to neighboring time steps.\n",
    "\n",
    "Because maximization of marginals and maximization of the joint distribution do not commute,\n",
    "the sequence formed by independently maximizing each marginal posterior does not, in general,\n",
    "maximize the joint posterior probability of the full trajectory.\n",
    "\n",
    "---\n",
    "\n",
    "## A counterexample\n",
    "\n",
    "Consider an HMM in which, at some time step \\(k\\),\n",
    "\n",
    "$$\n",
    "P(X_k = a \\mid Y_{1:t}) > P(X_k = b \\mid Y_{1:t}),\n",
    "$$\n",
    "\n",
    "so smoothing selects state \\(a\\) at time \\(k\\).\n",
    "\n",
    "However, suppose that the transition probabilities satisfy\n",
    "\n",
    "$$\n",
    "T_{a \\to c} \\approx 0,\n",
    "\\qquad\n",
    "T_{b \\to c} \\text{ is large},\n",
    "$$\n",
    "\n",
    "where \\(c\\) is the most likely state at time \\(k+1\\).\n",
    "\n",
    "In this case, although state \\(a\\) has a slightly higher marginal posterior probability at time \\(k\\),\n",
    "any trajectory passing through \\(a\\) has a very low joint probability due to the near-impossible\n",
    "transition to \\(c\\). As a result, the Viterbi algorithm selects state \\(b\\) at time \\(k\\) in order to\n",
    "maximize the joint probability of the entire trajectory.\n",
    "\n",
    "Thus, the state selected by smoothing at time \\(k\\) differs from the state chosen by Viterbi\n",
    "decoding.\n",
    "\n",
    "---\n",
    "\n",
    "## When are the two solutions the same?\n",
    "\n",
    "The two solutions coincide in special cases where temporal dependencies do not affect the\n",
    "optimal path. For example:\n",
    "\n",
    "1. **Independent states across time**  \n",
    "   If the states are independent (i.e., there is no meaningful state transition structure),\n",
    "   then the joint posterior factorizes into a product of marginal posteriors. In this case,\n",
    "   maximizing the joint probability is equivalent to maximizing each marginal independently.\n",
    "\n",
    "2. **Uniform or uninformative transition matrix**  \n",
    "   If the transition matrix assigns equal probability to all state transitions, the transitions\n",
    "   do not favor any particular path. Consequently, the Viterbi solution reduces to selecting\n",
    "   the most likely state at each time step, which matches the smoothing result.\n",
    "\n",
    "3. **Deterministic transitions**  \n",
    "   If the Markov chain allows only a single feasible transition from each state, then both\n",
    "   methods necessarily produce the same state sequence.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In general, the Viterbi decoding solution is not equal to the sequence obtained by selecting the\n",
    "most likely state at each time step from smoothing. Smoothing performs pointwise maximization\n",
    "of marginal posterior probabilities, whereas Viterbi decoding maximizes the joint posterior\n",
    "probability of the entire state trajectory. The two solutions coincide only in special cases\n",
    "where temporal dependencies do not influence the optimal path.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
